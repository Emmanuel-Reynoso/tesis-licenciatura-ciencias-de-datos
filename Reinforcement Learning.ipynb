{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e93e65d0",
   "metadata": {},
   "source": [
    "## Validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7dc528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import time\n",
    "from geopy.distance import geodesic\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict, deque\n",
    "import random\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class RLConfig:\n",
    "    \"\"\"Configuración de parámetros de Reinforcement Learning.\"\"\"\n",
    "    learning_rate: float = 0.2\n",
    "    discount_factor: float = 0.9\n",
    "    epsilon_start: float = 1.0\n",
    "    epsilon_end: float = 0.1\n",
    "    epsilon_decay: float = 0.98\n",
    "    max_episodes: int = 100\n",
    "    max_steps_per_episode: int = 25\n",
    "    memory_size: int = 5000\n",
    "    batch_size: int = 16\n",
    "    target_update_freq: int = 50\n",
    "\n",
    "@dataclass\n",
    "class SystemConfig:\n",
    "    \"\"\"Configuración general del sistema.\"\"\"\n",
    "    cantidad_de_rutas: int = 3\n",
    "    max_paradas_por_ruta: int = 15\n",
    "    radio_pois_metros: float = 500.0\n",
    "    mejora_minima_requerida: float = 25.0\n",
    "    distancia_maxima_movimiento: float = 150.0\n",
    "    crear_mapas_individuales: bool = True\n",
    "    crear_reportes: bool = True\n",
    "    verbose: bool = True\n",
    "    distancia_a_calle_maxima: float = 30.0\n",
    "\n",
    "class BusStopEnvironment:\n",
    "    \"\"\"Ambiente de RL para optimización de paradas de bus.\"\"\"\n",
    "    \n",
    "    def __init__(self, route_stops_df, colegios_df, hospitales_df, route_info, system_config):\n",
    "        \"\"\"\n",
    "        Inicializa el ambiente de RL para una ruta específica.\n",
    "        \n",
    "        Args:\n",
    "            route_stops_df (pd.DataFrame): DataFrame con paradas de la ruta\n",
    "            colegios_df (pd.DataFrame): DataFrame con colegios\n",
    "            hospitales_df (pd.DataFrame): DataFrame con hospitales\n",
    "            route_info (dict): Información de la ruta {'linea': X, 'sentido': Y}\n",
    "            system_config (SystemConfig): Configuración del sistema\n",
    "        \"\"\"\n",
    "        self.route_stops_df = route_stops_df\n",
    "        self.colegios_df = colegios_df\n",
    "        self.hospitales_df = hospitales_df\n",
    "        self.route_info = route_info\n",
    "        self.system_config = system_config\n",
    "        \n",
    "        self.current_stop_data = None\n",
    "        self.original_position = None\n",
    "        self.current_position = None\n",
    "        self.steps_taken = 0\n",
    "        self.max_steps = 50\n",
    "        \n",
    "        self._filter_nearby_pois()\n",
    "        \n",
    "        self.action_space_size = 40\n",
    "        self.directions = [\n",
    "            (-1, -1), (-1, 0), (-1, 1),\n",
    "            (0, -1),           (0, 1),\n",
    "            (1, -1),  (1, 0),  (1, 1)\n",
    "        ]\n",
    "        self.distances = [30, 60, 90, 120, 150]\n",
    "        self.state_size = 6\n",
    "        \n",
    "        if self.system_config.verbose:\n",
    "            print(f\"Ruta {route_info['linea']}-{route_info['sentido']}: {len(self.route_stops_df)} paradas, \"\n",
    "                  f\"Colegios: {len(self.nearby_colegios)}, Hospitales: {len(self.nearby_hospitales)}\")\n",
    "    \n",
    "    def _filter_nearby_pois(self):\n",
    "        \"\"\"Filtra POIs que están dentro del radio especificado de alguna parada de la ruta.\"\"\"\n",
    "        nearby_colegios = []\n",
    "        nearby_hospitales = []\n",
    "        \n",
    "        for _, stop in self.route_stops_df.iterrows():\n",
    "            stop_pos = (stop['lat'], stop['lon'])\n",
    "            \n",
    "            for _, colegio in self.colegios_df.iterrows():\n",
    "                colegio_pos = (colegio['lat'], colegio['lon'])\n",
    "                if geodesic(stop_pos, colegio_pos).meters <= self.system_config.radio_pois_metros:\n",
    "                    nearby_colegios.append(colegio)\n",
    "            \n",
    "            for _, hospital in self.hospitales_df.iterrows():\n",
    "                hospital_pos = (hospital['lat'], hospital['lon'])\n",
    "                if geodesic(stop_pos, hospital_pos).meters <= self.system_config.radio_pois_metros:\n",
    "                    nearby_hospitales.append(hospital)\n",
    "        \n",
    "        self.nearby_colegios = pd.DataFrame(nearby_colegios).drop_duplicates().reset_index(drop=True)\n",
    "        self.nearby_hospitales = pd.DataFrame(nearby_hospitales).drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "        if self.nearby_colegios.empty:\n",
    "            self.nearby_colegios = pd.DataFrame(columns=['nombre', 'lat', 'lon'])\n",
    "        if self.nearby_hospitales.empty:\n",
    "            self.nearby_hospitales = pd.DataFrame(columns=['nombre', 'lat', 'lon'])\n",
    "    \n",
    "    def reset(self, stop_data: Dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reinicia el ambiente para una nueva parada.\n",
    "        \n",
    "        Args:\n",
    "            stop_data (Dict): Datos de la parada a optimizar\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Estado inicial del ambiente\n",
    "        \"\"\"\n",
    "        self.current_stop_data = stop_data.copy()\n",
    "        self.original_position = (stop_data['lat'], stop_data['lon'])\n",
    "        self.current_position = self.original_position\n",
    "        self.steps_taken = 0\n",
    "        \n",
    "        return self._get_state()\n",
    "    \n",
    "    def _get_state(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Obtiene el estado actual del ambiente.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: Vector de estado [lat, lon, dist_colegio_min, dist_hospital_min, en_calle, dist_a_calle]\n",
    "        \"\"\"\n",
    "        lat, lon = self.current_position\n",
    "        \n",
    "        if not self.nearby_colegios.empty:\n",
    "            dist_colegios = [\n",
    "                geodesic((lat, lon), (row['lat'], row['lon'])).meters\n",
    "                for _, row in self.nearby_colegios.iterrows()\n",
    "            ]\n",
    "            min_dist_colegio = min(dist_colegios)\n",
    "        else:\n",
    "            min_dist_colegio = 1000.0\n",
    "        \n",
    "        if not self.nearby_hospitales.empty:\n",
    "            dist_hospitales = [\n",
    "                geodesic((lat, lon), (row['lat'], row['lon'])).meters\n",
    "                for _, row in self.nearby_hospitales.iterrows()\n",
    "            ]\n",
    "            min_dist_hospital = min(dist_hospitales)\n",
    "        else:\n",
    "            min_dist_hospital = 1000.0\n",
    "        \n",
    "        en_calle, dist_a_calle = self._is_on_street(lat, lon)\n",
    "        \n",
    "        return np.array([\n",
    "            lat, lon, \n",
    "            min_dist_colegio / 1000.0,\n",
    "            min_dist_hospital / 1000.0,\n",
    "            float(en_calle),\n",
    "            dist_a_calle / 100.0\n",
    "        ])\n",
    "    \n",
    "    def _is_on_street(self, lat: float, lon: float) -> Tuple[bool, float]:\n",
    "        \"\"\"\n",
    "        Verifica si una posición está en una calle usando heurística de grilla.\n",
    "        \n",
    "        Args:\n",
    "            lat (float): Latitud\n",
    "            lon (float): Longitud\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[bool, float]: (está_en_calle, distancia_a_calle)\n",
    "        \"\"\"\n",
    "        lat_local = (lat + 31.4) * 100000\n",
    "        lon_local = (lon + 64.2) * 100000\n",
    "        \n",
    "        lat_remainder = lat_local % 100\n",
    "        lon_remainder = lon_local % 100\n",
    "        \n",
    "        cerca_grilla_lat = (lat_remainder < 15 or lat_remainder > 85)\n",
    "        cerca_grilla_lon = (lon_remainder < 15 or lon_remainder > 85)\n",
    "        \n",
    "        en_calle = cerca_grilla_lat or cerca_grilla_lon\n",
    "        \n",
    "        if en_calle:\n",
    "            dist_a_calle = 0\n",
    "        else:\n",
    "            dist_lat = min(lat_remainder, 100 - lat_remainder)\n",
    "            dist_lon = min(lon_remainder, 100 - lon_remainder)\n",
    "            dist_a_calle = min(dist_lat, dist_lon) * 1.11\n",
    "        \n",
    "        return en_calle, dist_a_calle\n",
    "    \n",
    "    def _move_to_nearest_street(self, lat: float, lon: float) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Mueve una posición a la calle más cercana si está en una cuadra.\n",
    "        \n",
    "        Args:\n",
    "            lat (float): Latitud actual\n",
    "            lon (float): Longitud actual\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[float, float]: Nueva latitud y longitud en calle\n",
    "        \"\"\"\n",
    "        en_calle, dist_a_calle = self._is_on_street(lat, lon)\n",
    "        \n",
    "        if en_calle or dist_a_calle > self.system_config.distancia_a_calle_maxima:\n",
    "            return lat, lon\n",
    "        \n",
    "        lat_local = (lat + 31.4) * 100000\n",
    "        lon_local = (lon + 64.2) * 100000\n",
    "        \n",
    "        lat_remainder = lat_local % 100\n",
    "        lon_remainder = lon_local % 100\n",
    "        \n",
    "        if lat_remainder < 50:\n",
    "            lat_local = lat_local - lat_remainder\n",
    "        else:\n",
    "            lat_local = lat_local + (100 - lat_remainder)\n",
    "        \n",
    "        if lon_remainder < 50:\n",
    "            lon_local = lon_local - lon_remainder\n",
    "        else:\n",
    "            lon_local = lon_local + (100 - lon_remainder)\n",
    "        \n",
    "        new_lat = (lat_local / 100000) - 31.4\n",
    "        new_lon = (lon_local / 100000) - 64.2\n",
    "        \n",
    "        return new_lat, new_lon\n",
    "    \n",
    "    def step(self, action: int) -> Tuple[np.ndarray, float, bool, Dict]:\n",
    "        \"\"\"\n",
    "        Ejecuta una acción en el ambiente.\n",
    "        \n",
    "        Args:\n",
    "            action (int): Índice de la acción a ejecutar\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, float, bool, Dict]: (nuevo_estado, recompensa, terminado, info)\n",
    "        \"\"\"\n",
    "        self.steps_taken += 1\n",
    "        \n",
    "        direction_idx = action // len(self.distances)\n",
    "        distance_idx = action % len(self.distances)\n",
    "        \n",
    "        direction = self.directions[direction_idx]\n",
    "        distance = self.distances[distance_idx]\n",
    "        \n",
    "        lat, lon = self.current_position\n",
    "        \n",
    "        distance_deg_lat = distance / 111000\n",
    "        distance_deg_lon = distance / (111000 * abs(np.cos(np.radians(lat))))\n",
    "        \n",
    "        new_lat = lat + (direction[0] * distance_deg_lat)\n",
    "        new_lon = lon + (direction[1] * distance_deg_lon)\n",
    "        \n",
    "        if not (-32.0 <= new_lat <= -31.0 and -65.0 <= new_lon <= -64.0):\n",
    "            reward = -50\n",
    "            done = True\n",
    "            info = {'invalid_position': True}\n",
    "            return self._get_state(), reward, done, info\n",
    "        \n",
    "        old_position = self.current_position\n",
    "        self.current_position = (new_lat, new_lon)\n",
    "        \n",
    "        reward = self._calculate_reward(old_position, self.current_position)\n",
    "        \n",
    "        done = (self.steps_taken >= self.max_steps) or (reward > 100)\n",
    "        \n",
    "        info = {\n",
    "            'steps': self.steps_taken,\n",
    "            'improvement': reward,\n",
    "            'position_change': geodesic(old_position, self.current_position).meters\n",
    "        }\n",
    "        \n",
    "        return self._get_state(), reward, done, info\n",
    "    \n",
    "    def _calculate_reward(self, old_pos: Tuple[float, float], new_pos: Tuple[float, float]) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la recompensa basada en la mejora de posición.\n",
    "        \n",
    "        Args:\n",
    "            old_pos (Tuple[float, float]): Posición anterior\n",
    "            new_pos (Tuple[float, float]): Nueva posición\n",
    "            \n",
    "        Returns:\n",
    "            float: Recompensa calculada\n",
    "        \"\"\"\n",
    "        old_dist_colegio = self._min_distance_to_pois(old_pos, self.nearby_colegios)\n",
    "        old_dist_hospital = self._min_distance_to_pois(old_pos, self.nearby_hospitales)\n",
    "        old_min_poi = min(old_dist_colegio, old_dist_hospital)\n",
    "        \n",
    "        new_dist_colegio = self._min_distance_to_pois(new_pos, self.nearby_colegios)\n",
    "        new_dist_hospital = self._min_distance_to_pois(new_pos, self.nearby_hospitales)\n",
    "        new_min_poi = min(new_dist_colegio, new_dist_hospital)\n",
    "        \n",
    "        poi_improvement = old_min_poi - new_min_poi\n",
    "        \n",
    "        en_calle, dist_calle = self._is_on_street(new_pos[0], new_pos[1])\n",
    "        street_penalty = 0 if en_calle else -dist_calle * 0.5\n",
    "        \n",
    "        movement_distance = geodesic(old_pos, new_pos).meters\n",
    "        movement_penalty = -movement_distance * 0.1\n",
    "        \n",
    "        significant_bonus = 50 if poi_improvement > 50 else 0\n",
    "        \n",
    "        total_reward = poi_improvement + street_penalty + movement_penalty + significant_bonus\n",
    "        \n",
    "        return total_reward\n",
    "    \n",
    "    def _min_distance_to_pois(self, position: Tuple[float, float], pois_df: pd.DataFrame) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la distancia mínima a POIs.\n",
    "        \n",
    "        Args:\n",
    "            position (Tuple[float, float]): Posición de referencia\n",
    "            pois_df (pd.DataFrame): DataFrame con POIs\n",
    "            \n",
    "        Returns:\n",
    "            float: Distancia mínima en metros\n",
    "        \"\"\"\n",
    "        if pois_df.empty:\n",
    "            return 1000.0\n",
    "        \n",
    "        distances = [\n",
    "            geodesic(position, (row['lat'], row['lon'])).meters\n",
    "            for _, row in pois_df.iterrows()\n",
    "        ]\n",
    "        return min(distances)\n",
    "\n",
    "class QLearningAgent:\n",
    "    \"\"\"Agente Q-Learning para optimización de paradas.\"\"\"\n",
    "    \n",
    "    def __init__(self, state_size: int, action_size: int, config: RLConfig):\n",
    "        \"\"\"\n",
    "        Inicializa el agente Q-Learning.\n",
    "        \n",
    "        Args:\n",
    "            state_size (int): Tamaño del espacio de estados\n",
    "            action_size (int): Tamaño del espacio de acciones\n",
    "            config (RLConfig): Configuración de RL\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.config = config\n",
    "        \n",
    "        self.q_table = defaultdict(lambda: np.zeros(action_size))\n",
    "        self.epsilon = config.epsilon_start\n",
    "        self.memory = deque(maxlen=config.memory_size)\n",
    "        \n",
    "        self.training_stats = {\n",
    "            'episodes': [],\n",
    "            'rewards': [],\n",
    "            'steps': [],\n",
    "            'epsilon_values': []\n",
    "        }\n",
    "    \n",
    "    def _discretize_state(self, state: np.ndarray) -> str:\n",
    "        \"\"\"\n",
    "        Discretiza el estado continuo para la tabla Q.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): Estado continuo\n",
    "            \n",
    "        Returns:\n",
    "            str: Clave del estado discretizado\n",
    "        \"\"\"\n",
    "        lat_bin = int((state[0] + 31.5) * 50) // 5\n",
    "        lon_bin = int((state[1] + 64.5) * 50) // 5\n",
    "        dist_colegio_bin = min(int(state[2] * 5), 10)\n",
    "        dist_hospital_bin = min(int(state[3] * 5), 10)\n",
    "        en_calle_bin = int(state[4])\n",
    "        dist_calle_bin = min(int(state[5]), 5)\n",
    "        \n",
    "        return f\"{lat_bin}_{lon_bin}_{dist_colegio_bin}_{dist_hospital_bin}_{en_calle_bin}_{dist_calle_bin}\"\n",
    "    \n",
    "    def choose_action(self, state: np.ndarray, training: bool = True) -> int:\n",
    "        \"\"\"\n",
    "        Elige una acción usando estrategia epsilon-greedy.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): Estado actual\n",
    "            training (bool): Si está en modo entrenamiento\n",
    "            \n",
    "        Returns:\n",
    "            int: Índice de la acción elegida\n",
    "        \"\"\"\n",
    "        state_key = self._discretize_state(state)\n",
    "        \n",
    "        if training and random.random() < self.epsilon:\n",
    "            return random.randint(0, self.action_size - 1)\n",
    "        else:\n",
    "            q_values = self.q_table[state_key]\n",
    "            return np.argmax(q_values)\n",
    "    \n",
    "    def learn(self, state: np.ndarray, action: int, reward: float, \n",
    "              next_state: np.ndarray, done: bool):\n",
    "        \"\"\"\n",
    "        Actualiza la tabla Q basado en la experiencia.\n",
    "        \n",
    "        Args:\n",
    "            state (np.ndarray): Estado actual\n",
    "            action (int): Acción tomada\n",
    "            reward (float): Recompensa recibida\n",
    "            next_state (np.ndarray): Siguiente estado\n",
    "            done (bool): Si el episodio terminó\n",
    "        \"\"\"\n",
    "        state_key = self._discretize_state(state)\n",
    "        next_state_key = self._discretize_state(next_state)\n",
    "        \n",
    "        current_q = self.q_table[state_key][action]\n",
    "        \n",
    "        if done:\n",
    "            target_q = reward\n",
    "        else:\n",
    "            next_max_q = np.max(self.q_table[next_state_key])\n",
    "            target_q = reward + self.config.discount_factor * next_max_q\n",
    "        \n",
    "        self.q_table[state_key][action] = current_q + self.config.learning_rate * (target_q - current_q)\n",
    "        \n",
    "        if self.epsilon > self.config.epsilon_end:\n",
    "            self.epsilon *= self.config.epsilon_decay\n",
    "    \n",
    "    def train_episode(self, env: BusStopEnvironment, stop_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Entrena un episodio completo.\n",
    "        \n",
    "        Args:\n",
    "            env (BusStopEnvironment): Ambiente de entrenamiento\n",
    "            stop_data (Dict): Datos de la parada\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Resultados del episodio\n",
    "        \"\"\"\n",
    "        state = env.reset(stop_data)\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        \n",
    "        for step in range(self.config.max_steps_per_episode):\n",
    "            action = self.choose_action(state, training=True)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            self.learn(state, action, reward, next_state, done)\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            'total_reward': total_reward,\n",
    "            'steps': steps,\n",
    "            'final_position': env.current_position,\n",
    "            'improvement': total_reward\n",
    "        }\n",
    "\n",
    "class RouteOptimizer:\n",
    "    \"\"\"Optimizador de una ruta específica usando RL.\"\"\"\n",
    "    \n",
    "    def __init__(self, route_info: Dict, rl_config: RLConfig, system_config: SystemConfig):\n",
    "        \"\"\"\n",
    "        Inicializa el optimizador de ruta.\n",
    "        \n",
    "        Args:\n",
    "            route_info (Dict): Información de la ruta {'linea': X, 'sentido': Y}\n",
    "            rl_config (RLConfig): Configuración de RL\n",
    "            system_config (SystemConfig): Configuración del sistema\n",
    "        \"\"\"\n",
    "        self.route_info = route_info\n",
    "        self.rl_config = rl_config\n",
    "        self.system_config = system_config\n",
    "        \n",
    "        self.route_stops_df = None\n",
    "        self.colegios_df = None\n",
    "        self.hospitales_df = None\n",
    "        \n",
    "        self.environment = None\n",
    "        self.agent = None\n",
    "        \n",
    "        self.optimized_stops = []\n",
    "        self.training_history = {}\n",
    "    \n",
    "    def load_route_data(self, all_stops_df, colegios_df, hospitales_df):\n",
    "        \"\"\"\n",
    "        Carga los datos específicos de esta ruta.\n",
    "        \n",
    "        Args:\n",
    "            all_stops_df (pd.DataFrame): DataFrame con todas las paradas\n",
    "            colegios_df (pd.DataFrame): DataFrame con colegios\n",
    "            hospitales_df (pd.DataFrame): DataFrame con hospitales\n",
    "        \"\"\"\n",
    "        self.route_stops_df = all_stops_df[\n",
    "            (all_stops_df['linea'] == self.route_info['linea']) & \n",
    "            (all_stops_df['sentido'] == self.route_info['sentido'])\n",
    "        ].head(self.system_config.max_paradas_por_ruta).copy()\n",
    "        \n",
    "        self.colegios_df = colegios_df.copy()\n",
    "        self.hospitales_df = hospitales_df.copy()\n",
    "        \n",
    "        if self.system_config.verbose:\n",
    "            print(f\"Ruta {self.route_info['linea']}-{self.route_info['sentido']}: {len(self.route_stops_df)} paradas\")\n",
    "    \n",
    "    def setup_rl_components(self):\n",
    "        \"\"\"Configura el ambiente y agente de RL para esta ruta.\"\"\"\n",
    "        self.environment = BusStopEnvironment(\n",
    "            self.route_stops_df,\n",
    "            self.colegios_df, \n",
    "            self.hospitales_df,\n",
    "            self.route_info,\n",
    "            self.system_config\n",
    "        )\n",
    "        \n",
    "        self.agent = QLearningAgent(\n",
    "            state_size=self.environment.state_size,\n",
    "            action_size=self.environment.action_space_size,\n",
    "            config=self.rl_config\n",
    "        )\n",
    "    \n",
    "    def train_agent(self):\n",
    "        \"\"\"Entrena el agente en las paradas de esta ruta.\"\"\"\n",
    "        if self.system_config.verbose:\n",
    "            print(f\"Entrenando RL para {len(self.route_stops_df)} paradas...\")\n",
    "        \n",
    "        training_results = []\n",
    "        \n",
    "        for episode in range(self.rl_config.max_episodes):\n",
    "            stop_data = self.route_stops_df.sample(1).iloc[0].to_dict()\n",
    "            result = self.agent.train_episode(self.environment, stop_data)\n",
    "            training_results.append(result)\n",
    "            \n",
    "            self.agent.training_stats['episodes'].append(episode)\n",
    "            self.agent.training_stats['rewards'].append(result['total_reward'])\n",
    "            self.agent.training_stats['steps'].append(result['steps'])\n",
    "            self.agent.training_stats['epsilon_values'].append(self.agent.epsilon)\n",
    "        \n",
    "        self.training_history = {\n",
    "            'final_epsilon': self.agent.epsilon,\n",
    "            'avg_final_reward': np.mean([r['total_reward'] for r in training_results[-20:]]),\n",
    "            'total_episodes': len(training_results)\n",
    "        }\n",
    "    \n",
    "    def optimize_all_stops(self):\n",
    "        \"\"\"Optimiza todas las paradas de esta ruta.\"\"\"\n",
    "        if self.system_config.verbose:\n",
    "            print(f\"Optimizando {len(self.route_stops_df)} paradas...\")\n",
    "        \n",
    "        optimized_count = 0\n",
    "        \n",
    "        for _, stop in self.route_stops_df.iterrows():\n",
    "            try:\n",
    "                result = self._optimize_single_stop(stop.to_dict())\n",
    "                result.update({\n",
    "                    'linea': self.route_info['linea'],\n",
    "                    'sentido': self.route_info['sentido']\n",
    "                })\n",
    "                \n",
    "                self.optimized_stops.append(result)\n",
    "                \n",
    "                if result['relocated']:\n",
    "                    optimized_count += 1\n",
    "                        \n",
    "            except Exception as e:\n",
    "                error_result = stop.to_dict()\n",
    "                error_result.update({\n",
    "                    'relocated': False,\n",
    "                    'error': str(e),\n",
    "                    'linea': self.route_info['linea'],\n",
    "                    'sentido': self.route_info['sentido']\n",
    "                })\n",
    "                self.optimized_stops.append(error_result)\n",
    "        \n",
    "        if self.system_config.verbose:\n",
    "            print(f\"Resultado: {optimized_count}/{len(self.route_stops_df)} paradas optimizadas\")\n",
    "    \n",
    "    def _optimize_single_stop(self, stop_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Optimiza una parada individual.\n",
    "        \n",
    "        Args:\n",
    "            stop_data (Dict): Datos de la parada\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Resultado de la optimización\n",
    "        \"\"\"\n",
    "        state = self.environment.reset(stop_data)\n",
    "        \n",
    "        total_steps = 0\n",
    "        \n",
    "        for step in range(self.rl_config.max_steps_per_episode):\n",
    "            action = self.agent.choose_action(state, training=False)\n",
    "            next_state, reward, done, info = self.environment.step(action)\n",
    "            \n",
    "            state = next_state\n",
    "            total_steps += 1\n",
    "            \n",
    "            if done or reward > 50:\n",
    "                break\n",
    "        \n",
    "        rl_final_pos = self.environment.current_position\n",
    "        street_final_pos = self.environment._move_to_nearest_street(rl_final_pos[0], rl_final_pos[1])\n",
    "        \n",
    "        original_pos = (stop_data['lat'], stop_data['lon'])\n",
    "        \n",
    "        original_poi_dist = min(\n",
    "            self.environment._min_distance_to_pois(original_pos, self.environment.nearby_colegios),\n",
    "            self.environment._min_distance_to_pois(original_pos, self.environment.nearby_hospitales)\n",
    "        )\n",
    "        \n",
    "        street_poi_dist = min(\n",
    "            self.environment._min_distance_to_pois(street_final_pos, self.environment.nearby_colegios),\n",
    "            self.environment._min_distance_to_pois(street_final_pos, self.environment.nearby_hospitales)\n",
    "        )\n",
    "        \n",
    "        improvement = original_poi_dist - street_poi_dist\n",
    "        \n",
    "        result = stop_data.copy()\n",
    "        result.update({\n",
    "            'relocated': improvement > self.system_config.mejora_minima_requerida,\n",
    "            'improvement_meters': improvement,\n",
    "            'rl_steps_taken': total_steps,\n",
    "            'rl_raw_position': rl_final_pos,\n",
    "            'street_adjusted_position': street_final_pos,\n",
    "        })\n",
    "        \n",
    "        if result['relocated']:\n",
    "            result.update({\n",
    "                'lat_original': original_pos[0],\n",
    "                'lon_original': original_pos[1],\n",
    "                'lat': street_final_pos[0],\n",
    "                'lon': street_final_pos[1],\n",
    "                'movement_distance_meters': geodesic(original_pos, street_final_pos).meters\n",
    "            })\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def create_route_map(self):\n",
    "        \"\"\"\n",
    "        Crea un mapa interactivo específico de esta ruta.\n",
    "        \n",
    "        Returns:\n",
    "            folium.Map: Mapa de la ruta optimizada\n",
    "        \"\"\"\n",
    "        if not self.optimized_stops:\n",
    "            return None\n",
    "        \n",
    "        route_name = f\"{self.route_info['linea']}-{self.route_info['sentido']}\"\n",
    "        \n",
    "        lats = [stop['lat'] for stop in self.optimized_stops]\n",
    "        lons = [stop['lon'] for stop in self.optimized_stops]\n",
    "        \n",
    "        center_lat = np.mean(lats)\n",
    "        center_lon = np.mean(lons)\n",
    "        \n",
    "        m = folium.Map(\n",
    "            location=[center_lat, center_lon],\n",
    "            zoom_start=14,\n",
    "            tiles='OpenStreetMap'\n",
    "        )\n",
    "        \n",
    "        paradas_originales = folium.FeatureGroup(name='Ubicaciones Originales', show=True)\n",
    "        paradas_optimizadas = folium.FeatureGroup(name='Optimizadas por RL', show=True)\n",
    "        paradas_sin_cambios = folium.FeatureGroup(name='Sin Cambios', show=True)\n",
    "        colegios_layer = folium.FeatureGroup(name='Colegios Cercanos', show=True)\n",
    "        hospitales_layer = folium.FeatureGroup(name='Hospitales Cercanos', show=True)\n",
    "        \n",
    "        count_optimizadas = 0\n",
    "        total_mejora = 0\n",
    "        \n",
    "        for stop in self.optimized_stops:\n",
    "            nombre = stop['parada_nombre']\n",
    "            \n",
    "            if stop.get('relocated', False):\n",
    "                lat_orig = stop['lat_original']\n",
    "                lon_orig = stop['lon_original']\n",
    "                lat_final = stop['lat']\n",
    "                lon_final = stop['lon']\n",
    "                mejora = stop.get('improvement_meters', 0)\n",
    "                \n",
    "                folium.CircleMarker(\n",
    "                    location=[lat_orig, lon_orig],\n",
    "                    radius=8,\n",
    "                    popup=f\"ORIGINAL: {nombre}\",\n",
    "                    tooltip=f\"Original: {nombre}\",\n",
    "                    color='#d32f2f',\n",
    "                    fillColor='#f44336',\n",
    "                    fillOpacity=0.8,\n",
    "                    weight=3\n",
    "                ).add_to(paradas_originales)\n",
    "                \n",
    "                folium.CircleMarker(\n",
    "                    location=[lat_final, lon_final],\n",
    "                    radius=10,\n",
    "                    popup=f\"OPTIMIZADA: {nombre} (+{mejora:.1f}m)\",\n",
    "                    tooltip=f\"{nombre} (+{mejora:.0f}m)\",\n",
    "                    color='#2e7d32',\n",
    "                    fillColor='#4caf50',\n",
    "                    fillOpacity=0.9,\n",
    "                    weight=4\n",
    "                ).add_to(paradas_optimizadas)\n",
    "                \n",
    "                folium.PolyLine(\n",
    "                    locations=[[lat_orig, lon_orig], [lat_final, lon_final]],\n",
    "                    color='#2e7d32',\n",
    "                    weight=4,\n",
    "                    opacity=0.9,\n",
    "                    popup=f\"Mejora: {mejora:.1f}m\",\n",
    "                    tooltip=f\"Mejora: +{mejora:.0f}m\"\n",
    "                ).add_to(paradas_optimizadas)\n",
    "                \n",
    "                count_optimizadas += 1\n",
    "                total_mejora += mejora\n",
    "                \n",
    "            else:\n",
    "                lat_actual = stop['lat']\n",
    "                lon_actual = stop['lon']\n",
    "                \n",
    "                folium.CircleMarker(\n",
    "                    location=[lat_actual, lon_actual],\n",
    "                    radius=6,\n",
    "                    popup=f\"SIN CAMBIOS: {nombre}\",\n",
    "                    tooltip=f\"{nombre} (sin cambios)\",\n",
    "                    color='#1976d2',\n",
    "                    fillColor='#2196f3',\n",
    "                    fillOpacity=0.7,\n",
    "                    weight=2\n",
    "                ).add_to(paradas_sin_cambios)\n",
    "        \n",
    "        for _, colegio in self.environment.nearby_colegios.iterrows():\n",
    "            folium.Marker(\n",
    "                location=[colegio['lat'], colegio['lon']],\n",
    "                popup=f\"Colegio: {colegio['nombre']}\",\n",
    "                icon=folium.Icon(color='purple', icon='graduation-cap', prefix='fa')\n",
    "            ).add_to(colegios_layer)\n",
    "        \n",
    "        for _, hospital in self.environment.nearby_hospitales.iterrows():\n",
    "            folium.Marker(\n",
    "                location=[hospital['lat'], hospital['lon']],\n",
    "                popup=f\"Hospital: {hospital['nombre']}\",\n",
    "                icon=folium.Icon(color='red', icon='plus', prefix='fa')\n",
    "            ).add_to(hospitales_layer)\n",
    "        \n",
    "        paradas_originales.add_to(m)\n",
    "        paradas_optimizadas.add_to(m)\n",
    "        paradas_sin_cambios.add_to(m)\n",
    "        colegios_layer.add_to(m)\n",
    "        hospitales_layer.add_to(m)\n",
    "        \n",
    "        folium.LayerControl(position='topleft', collapsed=False).add_to(m)\n",
    "        \n",
    "        os.makedirs('mapas_por_ruta', exist_ok=True)\n",
    "        filename = f'mapas_por_ruta/ruta_{route_name.replace(\"-\", \"_\")}.html'\n",
    "        m.save(filename)\n",
    "        \n",
    "        return m\n",
    "    \n",
    "    def get_results_summary(self):\n",
    "        \"\"\"\n",
    "        Obtiene un resumen de los resultados de esta ruta.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Resumen de resultados\n",
    "        \"\"\"\n",
    "        if not self.optimized_stops:\n",
    "            return {}\n",
    "        \n",
    "        optimized_count = len([s for s in self.optimized_stops if s.get('relocated', False)])\n",
    "        total_improvement = sum([s.get('improvement_meters', 0) for s in self.optimized_stops if s.get('relocated', False)])\n",
    "        \n",
    "        return {\n",
    "            'route_info': self.route_info,\n",
    "            'total_stops': len(self.optimized_stops),\n",
    "            'optimized_stops': optimized_count,\n",
    "            'success_rate': (optimized_count / len(self.optimized_stops)) * 100,\n",
    "            'total_improvement_meters': total_improvement,\n",
    "            'avg_improvement_meters': total_improvement / optimized_count if optimized_count > 0 else 0,\n",
    "            'nearby_colegios': len(self.environment.nearby_colegios),\n",
    "            'nearby_hospitales': len(self.environment.nearby_hospitales)\n",
    "        }\n",
    "\n",
    "class RLBusStopRelocator:\n",
    "    \"\"\"Sistema principal que procesa ruta por ruta.\"\"\"\n",
    "    \n",
    "    def __init__(self, rl_config: RLConfig = None, system_config: SystemConfig = None):\n",
    "        \"\"\"\n",
    "        Inicializa el sistema de reubicación de paradas.\n",
    "        \n",
    "        Args:\n",
    "            rl_config (RLConfig, optional): Configuración de RL\n",
    "            system_config (SystemConfig, optional): Configuración del sistema\n",
    "        \"\"\"\n",
    "        self.rl_config = rl_config or RLConfig()\n",
    "        self.system_config = system_config or SystemConfig()\n",
    "        \n",
    "        self.df_paradas = None\n",
    "        self.df_colegios = None\n",
    "        self.df_hospitales = None\n",
    "        \n",
    "        self.route_optimizers = {}\n",
    "        self.all_results = []\n",
    "        self.routes_summary = []\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Carga los datasets necesarios.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True si los datos se cargaron correctamente\n",
    "        \"\"\"\n",
    "        try:\n",
    "            paths_to_try = [\n",
    "                '../1_preprocess/0_EDA/result/2_rutas_paradas.csv',\n",
    "                '../1_preprocess/0_EDA/result/3_barrios_cordoba_escuelas.csv', \n",
    "                '../1_preprocess/0_EDA/result/4_centros_de_salud_municipales_cordoba.csv'\n",
    "            ]\n",
    "            \n",
    "            if not any(os.path.exists(path) for path in paths_to_try):\n",
    "                self._create_sample_data()\n",
    "                return True\n",
    "            \n",
    "            self.df_paradas = pd.read_csv('../1_preprocess/0_EDA/result/2_rutas_paradas.csv')\n",
    "            self.df_colegios = pd.read_csv('../1_preprocess/0_EDA/result/3_barrios_cordoba_escuelas.csv')\n",
    "            self.df_hospitales = pd.read_csv('../1_preprocess/0_EDA/result/4_centros_de_salud_municipales_cordoba.csv')\n",
    "            \n",
    "            self.df_paradas = self.df_paradas.dropna(subset=['lat', 'lon'])\n",
    "            self.df_colegios = self.df_colegios.dropna(subset=['lat', 'lon'])\n",
    "            self.df_hospitales = self.df_hospitales.dropna(subset=['lat', 'lon'])\n",
    "            \n",
    "            if self.system_config.verbose:\n",
    "                print(f\"Datos cargados - Paradas: {len(self.df_paradas)}, \"\n",
    "                      f\"Colegios: {len(self.df_colegios)}, Hospitales: {len(self.df_hospitales)}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando datos: {e}\")\n",
    "            self._create_sample_data()\n",
    "            return True\n",
    "    \n",
    "    def _create_sample_data(self):\n",
    "        \"\"\"Crea datos de ejemplo para Córdoba.\"\"\"\n",
    "        print(\"Creando datos de ejemplo para Córdoba...\")\n",
    "        \n",
    "        cordoba_center = (-31.4201, -64.1888)\n",
    "        \n",
    "        paradas_data = []\n",
    "        lineas = ['A', 'B', 'C', 'D']\n",
    "        sentidos = ['I', 'V']\n",
    "        \n",
    "        for i, linea in enumerate(lineas):\n",
    "            for j, sentido in enumerate(sentidos):\n",
    "                num_paradas = random.randint(8, 15)\n",
    "                for k in range(num_paradas):\n",
    "                    offset_lat = (i - 1.5) * 0.02 + (k * 0.005)\n",
    "                    offset_lon = (j - 0.5) * 0.02 + (k * 0.003)\n",
    "                    \n",
    "                    lat = cordoba_center[0] + offset_lat + np.random.normal(0, 0.001)\n",
    "                    lon = cordoba_center[1] + offset_lon + np.random.normal(0, 0.001)\n",
    "                    \n",
    "                    paradas_data.append({\n",
    "                        'parada_nombre': f'Parada {linea}{k+1}',\n",
    "                        'lat': lat,\n",
    "                        'lon': lon,\n",
    "                        'linea': linea,\n",
    "                        'sentido': sentido,\n",
    "                        'codigo': f'P{linea}{sentido}{k+1:02d}'\n",
    "                    })\n",
    "        \n",
    "        colegios_data = []\n",
    "        for i in range(25):\n",
    "            lat = cordoba_center[0] + np.random.normal(0, 0.03)\n",
    "            lon = cordoba_center[1] + np.random.normal(0, 0.03)\n",
    "            colegios_data.append({\n",
    "                'nombre': f'Colegio {i+1}',\n",
    "                'lat': lat,\n",
    "                'lon': lon\n",
    "            })\n",
    "        \n",
    "        hospitales_data = []\n",
    "        for i in range(15):\n",
    "            lat = cordoba_center[0] + np.random.normal(0, 0.025)\n",
    "            lon = cordoba_center[1] + np.random.normal(0, 0.025)\n",
    "            hospitales_data.append({\n",
    "                'nombre': f'Hospital {i+1}',\n",
    "                'lat': lat,\n",
    "                'lon': lon\n",
    "            })\n",
    "        \n",
    "        self.df_paradas = pd.DataFrame(paradas_data)\n",
    "        self.df_colegios = pd.DataFrame(colegios_data)\n",
    "        self.df_hospitales = pd.DataFrame(hospitales_data)\n",
    "    \n",
    "    def process_all_routes(self):\n",
    "        \"\"\"\n",
    "        Procesa todas las rutas individualmente.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame con todos los resultados\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if not self.load_data():\n",
    "            return None\n",
    "        \n",
    "        available_routes = self.df_paradas[['linea', 'sentido']].drop_duplicates()\n",
    "        selected_routes = available_routes.head(self.system_config.cantidad_de_rutas)\n",
    "        \n",
    "        print(f\"Procesando {len(selected_routes)} rutas...\")\n",
    "        \n",
    "        for _, route_row in selected_routes.iterrows():\n",
    "            route_info = {\n",
    "                'linea': route_row['linea'],\n",
    "                'sentido': route_row['sentido']\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                route_optimizer = RouteOptimizer(route_info, self.rl_config, self.system_config)\n",
    "                route_optimizer.load_route_data(self.df_paradas, self.df_colegios, self.df_hospitales)\n",
    "                route_optimizer.setup_rl_components()\n",
    "                route_optimizer.train_agent()\n",
    "                route_optimizer.optimize_all_stops()\n",
    "                route_optimizer.create_route_map()\n",
    "                \n",
    "                self.route_optimizers[f\"{route_info['linea']}-{route_info['sentido']}\"] = route_optimizer\n",
    "                self.all_results.extend(route_optimizer.optimized_stops)\n",
    "                \n",
    "                summary = route_optimizer.get_results_summary()\n",
    "                self.routes_summary.append(summary)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando ruta {route_info['linea']}-{route_info['sentido']}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        self._create_final_summary(total_time)\n",
    "        \n",
    "        return pd.DataFrame(self.all_results)\n",
    "    \n",
    "    def _create_final_summary(self, total_time: float):\n",
    "        \"\"\"\n",
    "        Crea un resumen final de todas las rutas procesadas.\n",
    "        \n",
    "        Args:\n",
    "            total_time (float): Tiempo total de procesamiento\n",
    "        \"\"\"\n",
    "        if not self.routes_summary:\n",
    "            return\n",
    "        \n",
    "        total_stops = sum([r['total_stops'] for r in self.routes_summary])\n",
    "        total_optimized = sum([r['optimized_stops'] for r in self.routes_summary])\n",
    "        total_improvement = sum([r['total_improvement_meters'] for r in self.routes_summary])\n",
    "        \n",
    "        print(f\"\\nResumen final:\")\n",
    "        print(f\"Tiempo total: {total_time:.1f}s\")\n",
    "        print(f\"Rutas procesadas: {len(self.routes_summary)}\")\n",
    "        print(f\"Paradas totales: {total_stops}\")\n",
    "        print(f\"Paradas optimizadas: {total_optimized}\")\n",
    "        print(f\"Tasa de éxito: {(total_optimized/total_stops)*100:.1f}%\")\n",
    "        print(f\"Mejora total: {total_improvement:.1f} metros\")\n",
    "        \n",
    "        os.makedirs('reportes', exist_ok=True)\n",
    "        \n",
    "        summary_data = {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'processing_time_seconds': total_time,\n",
    "            'total_routes': len(self.routes_summary),\n",
    "            'total_stops': total_stops,\n",
    "            'total_optimized': total_optimized,\n",
    "            'global_success_rate': (total_optimized/total_stops)*100,\n",
    "            'total_improvement_meters': total_improvement,\n",
    "            'routes_detail': self.routes_summary\n",
    "        }\n",
    "        \n",
    "        with open('reportes/resumen_rutas_rl.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "def main_rl_rutas(\n",
    "    cantidad_de_rutas: int = 3,\n",
    "    max_paradas_por_ruta: int = 12,\n",
    "    learning_rate: float = 0.2,\n",
    "    discount_factor: float = 0.9,\n",
    "    epsilon_start: float = 1.0,\n",
    "    epsilon_end: float = 0.1,\n",
    "    epsilon_decay: float = 0.98,\n",
    "    max_episodes: int = 80,\n",
    "    max_steps_per_episode: int = 25,\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Función principal para procesamiento RL ruta por ruta.\n",
    "    \n",
    "    Args:\n",
    "        cantidad_de_rutas (int): Número de rutas a procesar\n",
    "        max_paradas_por_ruta (int): Máximo de paradas por ruta\n",
    "        learning_rate (float): Tasa de aprendizaje\n",
    "        discount_factor (float): Factor de descuento\n",
    "        epsilon_start (float): Epsilon inicial\n",
    "        epsilon_end (float): Epsilon final\n",
    "        epsilon_decay (float): Decaimiento de epsilon\n",
    "        max_episodes (int): Máximo número de episodios\n",
    "        max_steps_per_episode (int): Máximo pasos por episodio\n",
    "        verbose (bool): Si mostrar información detallada\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Resultados de la optimización\n",
    "    \"\"\"\n",
    "    \n",
    "    rl_config = RLConfig(\n",
    "        learning_rate=learning_rate,\n",
    "        discount_factor=discount_factor,\n",
    "        epsilon_start=epsilon_start,\n",
    "        epsilon_end=epsilon_end,\n",
    "        epsilon_decay=epsilon_decay,\n",
    "        max_episodes=max_episodes,\n",
    "        max_steps_per_episode=max_steps_per_episode\n",
    "    )\n",
    "    \n",
    "    system_config = SystemConfig(\n",
    "        cantidad_de_rutas=cantidad_de_rutas,\n",
    "        max_paradas_por_ruta=max_paradas_por_ruta,\n",
    "        radio_pois_metros=500.0,\n",
    "        mejora_minima_requerida=25.0,\n",
    "        distancia_maxima_movimiento=150.0,\n",
    "        crear_mapas_individuales=True,\n",
    "        crear_reportes=True,\n",
    "        verbose=verbose,\n",
    "        distancia_a_calle_maxima=30.0\n",
    "    )\n",
    "    \n",
    "    rl_system = RLBusStopRelocator(rl_config, system_config)\n",
    "    result = rl_system.process_all_routes()\n",
    "    \n",
    "    if result is not None and not result.empty:\n",
    "        result.to_csv('reportes/resultados_rl_por_ruta.csv', index=False)\n",
    "        print(\"Resultados guardados en: resultados_rl_por_ruta.csv\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"No se pudieron procesar las rutas\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Sistema de Optimización RL para Paradas de Bus\")\n",
    "    \n",
    "    main_rl_rutas(\n",
    "        cantidad_de_rutas=3,\n",
    "        max_paradas_por_ruta=12,\n",
    "        max_episodes=80,\n",
    "        learning_rate=0.25,\n",
    "        verbose=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno-tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
